# 开发杂记



## rdma-redis

### 待办

- [x] 考虑使用sds来管理缓冲区大小
  - [ ] client端不需要改变缓冲区大小，固定100MB（需要做实验）

- [x] 目前每次rdma_init都是重新申请一遍信息，再重新建立连接。因为子进程在bgsave之后会被杀掉，之前的信息都会消失。如果将rdma_init放到server.c中，则会出现client端重启需要重新建立连接，但是server端没有监听端口。
- [x] 读取时需要判断是否为空，如果为空，则返回RDB_NOT_EXIST
- [x] 每写满一个buffer，就rdma_write一次。但是要重新考虑cnt的问题，不能放到buffer中了
- [x] server端每次交换信息都会建立、删除tcp链接，从而需要sleep。改为不删除、不sleep
- [ ] 确定要使用什么样的qp_type: RC、UC、UD、XRC
- [ ] 给rdma_read加上pingpong
- [x] 将rdma_init放到主进程意味着，fork之后buffer变成了COW的，因此所有的写入都会触发COW，造成性能下降
  - [ ] 实际上应该是fork之后buffer没办法用了，rdma_write/read都是针对原来的buffer
  - [ ] 需要将buffer设置为shared

- [ ] 使用mmap分配buffer后，并没有分配实际物理页，在第一次写入buffer时会触发较多缺页异常
  - [ ] 可以用memset处理

- [ ] 做实验的时候记得把AOF关了
- [ ] 父进程分配rdma资源子进程中，这个行为官方不建议。详见https://www.rdmamojo.com/2012/05/24/ibv_fork_init/最后一段

### 已解决

- rdma_init

### 机制设计

- server buffer最开头的0-3个字节用于写入一个cnt，记录server中数据的长度
- 4-7个字节用于写入一个信号，通知server是否结束rdma传输

### 好词好句

- **overlap**（HERD: mask the memory access latency by overlapping memory accesses of one request with computation of another request.）、**prefetch**(HERD: The server process expects the issued prefetches to finish by the time post send() returns.）、**pipline scheme**：用来解释buffer-pingpong的问题



### BUG记录

- 能够顺利读取rdma，但是写入始终失败
  - 在fork之前rdma_init，导致buffer是父进程的，因此子进程调用rdma_read后，写入到了父进程的buffer中；调用rdma_write后，从父进程的buffer中写入，故而失效
  - “顺利读取rdma”是在server.c调用rdma_init成功读取，此时是父进程，可以成功
  - 解决方法：使用mmap分配buffer，并设置为shared
- 莫名其妙的吧rdma的total_size给改成0了
  - rdma_init时的rdma_read只在第一次执行，后续不执行了，就变成了直接从buffer读
  - 改成每次都rdma_read就好了
- rdma_done能写入data_size, rdma_close写入不了RDMA_DONE
  - rdma_close时post_write传递的buffer地址还是mr->addr
